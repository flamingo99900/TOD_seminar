{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение в обработку текста на естественном языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Материалы:\n",
    "* Макрушин С.В. Лекция 9: Введение в обработку текста на естественном языке\\\n",
    "* https://realpython.com/nltk-nlp-python/\n",
    "* https://scikit-learn.org/stable/modules/feature_extraction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in d:\\anaconda\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: docopt>=0.6 in d:\\anaconda\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in d:\\anaconda\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in d:\\anaconda\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расстояние редактирования"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Загрузите предобработанные описания рецептов из файла `preprocessed_descriptions.csv`. Получите набор уникальных слов `words`, содержащихся в текстах описаний рецептов (воспользуйтесь `word_tokenize` из `nltk`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "recipes_df = pd.read_csv('preprocessed_descriptions.csv')\n",
    "words = []\n",
    "for description in recipes_df['description']:\n",
    "    words += word_tokenize(description)\n",
    "\n",
    "words = set(words)\n",
    "\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Сгенерируйте 5 пар случайно выбранных слов и посчитайте между ними расстояние редактирования."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Расстояние редактирования между \"ноутбук\" и \"банан\" равно 7\n",
      "Расстояние редактирования между \"ноутбук\" и \"автомобиль\" равно 8\n",
      "Расстояние редактирования между \"стул\" и \"автомобиль\" равно 8\n",
      "Расстояние редактирования между \"банан\" и \"шарф\" равно 4\n",
      "Расстояние редактирования между \"дерево\" и \"автомобиль\" равно 9\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from nltk.metrics import *\n",
    "\n",
    "words = ['стул', 'столик', 'автомобиль', 'банан', 'дерево', 'дом', 'книга', 'ноутбук', 'молоко', 'шарф']\n",
    "\n",
    "for i in range(5):\n",
    "    word1, word2 = random.sample(words, 2)\n",
    "    distance = edit_distance(word1, word2)\n",
    "    print(f'Расстояние редактирования между \"{word1}\" и \"{word2}\" равно {distance}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Напишите функцию, которая для заданного слова `word` возвращает `k` ближайших к нему слов из списка `words` (близость слов измеряется с помощью расстояния Левенштейна)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['дерево', 'дом', 'молоко']\n"
     ]
    }
   ],
   "source": [
    "def get_closest_words(word, words, k):\n",
    "    distances = {w: edit_distance(word, w) for w in words}\n",
    "    r = sorted(distances, key=distances.get)[:k]\n",
    "    return r\n",
    "\n",
    "print(get_closest_words('дерево', words, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стемминг, лемматизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 На основе результатов 1.1 создайте `pd.DataFrame` со столбцами: \n",
    "    * word\n",
    "    * stemmed_word \n",
    "    * normalized_word \n",
    "\n",
    "Столбец `word` укажите в качестве индекса. \n",
    "\n",
    "Для стемминга воспользуйтесь `SnowballStemmer`, для нормализации слов - `WordNetLemmatizer`. Сравните результаты стемминга и лемматизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df = pd.DataFrame(index=word, columns=['word', 'stemmed_word', 'normalized_word'])\n",
    "\n",
    "for word in words:\n",
    "    df.at[word, 'word'] = word\n",
    "    df.at[word, 'stemmed_word'] = stemmer.stem(word)\n",
    "    df.at[word, 'normalized_word'] = lemmatizer.lemmatize(word)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. Удалите стоп-слова из описаний рецептов. Какую долю об общего количества слов составляли стоп-слова? Сравните топ-10 самых часто употребляемых слов до и после удаления стоп-слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'same', 'from', 'you', 'then', 'myself', 'does', 'o', 't', 'this', 'more', 'having', 'these', 'on', 'my', 'which', 'i', 'only', 'hadn', 'above', 'for', \"doesn't\", 'him', 'because', 'while', 'haven', 'it', 'has', 'themselves', 'will', 's', 'be', 'are', 'isn', 'some', 'can', 'no', 'and', 'with', 'after', \"you'd\", 'out', \"mightn't\", 'whom', 'she', \"you'll\", 'all', 'or', 'hasn', 'off', 'just', \"haven't\", 'the', 'not', 'its', \"should've\", 'if', 'such', 'aren', 'why', \"hasn't\", 'over', 'when', 'below', 'up', 'should', 'mightn', \"couldn't\", 'shan', \"shouldn't\", 'both', 'd', 'an', 'of', 'a', 'once', \"mustn't\", 'those', 'too', 'doing', \"needn't\", 'most', 'wouldn', 'between', \"don't\", \"isn't\", 'at', 'needn', 'where', 'your', \"she's\", 'their', 'here', 'ma', 'her', 'so', 'wasn', 'don', 'to', 'his', 'being', \"you're\", 'll', 'yourself', 'himself', \"wasn't\", 'but', 'in', 'didn', \"weren't\", 'as', 'they', 'any', 'is', \"that'll\", 'about', 'than', 'down', 'very', 'now', 'won', 'how', 'mustn', 'had', 'couldn', 'ourselves', 'herself', 'further', \"it's\", 'our', 'm', 'nor', 'am', 'was', 'ours', 'few', \"didn't\", \"hadn't\", 'do', 'theirs', 'weren', 'each', 'until', 'who', 'we', 'yours', 'against', 'have', 'doesn', \"wouldn't\", 'did', 'own', 'into', \"shan't\", 've', 'there', 'shouldn', 'been', 'under', 'ain', 'by', 'y', \"aren't\", 'what', 'again', \"you've\", 'were', \"won't\", 'other', 'hers', 'through', 'yourselves', 'them', 'that', 'itself', 'me', 'he', 'during', 're', 'before'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)\n",
    "filtered_words = [w for w in words if w.lower() not in stop_words]\n",
    "\n",
    "top10_before = pd.Series(words).value_counts().head(10)\n",
    "top10_after = pd.Series(filtered_words).value_counts().head(10)\n",
    "\n",
    "stop_words_count = len([w for w in words if w.lower() in stop_words])\n",
    "total_words_count = len(words)\n",
    "stop_words_ratio = stop_words_count / total_words_count\n",
    "\n",
    "print(\"Доля стоп-слов в общем количестве слов:\"(stop_words_ratio))\n",
    "print(f\"Топ-10 самых часто употребляемых слов до удаления стоп-слов:{top10_before}\")\n",
    "print(f\"Топ-10 самых часто употребляемых слов после удаления стоп-слов:{top10_after}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторное представление текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Выберите случайным образом 5 рецептов из набора данных. Представьте описание каждого рецепта в виде числового вектора при помощи `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Рецепт 189: 30 minute lemon meringue pie\n",
      "Векторное описание: [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.38898761 0.         0.         0.\n",
      "  0.         0.         0.         0.48214012 0.         0.\n",
      "  0.         0.         0.48214012 0.         0.         0.\n",
      "  0.         0.         0.48214012 0.         0.38898761 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]]\n",
      "Рецепт 12568: greek mojito\n",
      "Векторное описание: [[0.         0.         0.         0.         0.40824829 0.40824829\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.40824829 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.40824829 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.40824829 0.         0.40824829]]\n",
      "Рецепт 17469: mexican chilli and cheese dip\n",
      "Векторное описание: [[0.34299717 0.34299717 0.17149859 0.17149859 0.         0.\n",
      "  0.17149859 0.17149859 0.         0.         0.         0.17149859\n",
      "  0.         0.17149859 0.17149859 0.         0.17149859 0.17149859\n",
      "  0.17149859 0.17149859 0.         0.17149859 0.         0.17149859\n",
      "  0.         0.17149859 0.         0.         0.         0.17149859\n",
      "  0.17149859 0.17149859 0.17149859 0.         0.17149859 0.17149859\n",
      "  0.17149859 0.17149859 0.         0.34299717 0.        ]]\n",
      "Рецепт 9440: different green bean casserole\n",
      "Векторное описание: [[0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.        0.4472136 0.4472136 0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.        0.\n",
      "  0.        0.4472136 0.        0.4472136 0.        0.        0.\n",
      "  0.        0.        0.        0.        0.        0.4472136 0.\n",
      "  0.        0.        0.        0.        0.        0.       ]]\n",
      "Рецепт 2710: beefy alphabet soup\n",
      "Векторное описание: [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.70710678 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.70710678 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df = pd.read_csv('recipes_sample.csv')\n",
    "random_recipes = df.sample(n=5)\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "vectors = vectorizer.fit_transform(random_recipes['description'])\n",
    "\n",
    "k = 0\n",
    "for i, recipe in random_recipes.iterrows():\n",
    "    print(f\"Рецепт {i+1}: {recipe['name']}\")\n",
    "    print(f\"Векторное описание: {vectors[k].toarray()}\")\n",
    "    k += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Вычислите близость между каждой парой рецептов, выбранных в задании 3.1, используя косинусное расстояние (`scipy.spatial.distance.cosine`) Результаты оформите в виде таблицы `pd.DataFrame`. В качестве названий строк и столбцов используйте названия рецептов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "description  for a quick and easy lemon meringue pie  \\\n",
      "0                                           1.000000   \n",
      "1                                           0.000000   \n",
      "2                                           0.000000   \n",
      "3                                           0.000000   \n",
      "4                                           0.550112   \n",
      "\n",
      "description  greek version of the cuba deliciousness!  posted for zwt #6...  \\\n",
      "0                                                          0.0                \n",
      "1                                                          1.0                \n",
      "2                                                          0.0                \n",
      "3                                                          0.0                \n",
      "4                                                          0.0                \n",
      "\n",
      "description  i first had this in a mexican restaurant in the venetian hotel in las vegas, the night before we got married. we loved it so much we virtually drank it and licked the bowl clean! this is the closest i've come to replicating it, and whenever i serve it, i see other people virtually drinking it and licking the bowl clean!  you can also use this as a sauce!  \\\n",
      "0                                                          0.0                                                                                                                                                                                                                                                                                                                      \n",
      "1                                                          0.0                                                                                                                                                                                                                                                                                                                      \n",
      "2                                                          1.0                                                                                                                                                                                                                                                                                                                      \n",
      "3                                                          0.0                                                                                                                                                                                                                                                                                                                      \n",
      "4                                                          0.0                                                                                                                                                                                                                                                                                                                      \n",
      "\n",
      "description  no mushroom soup or french fried onions in this one!  \\\n",
      "0                                                          0.0      \n",
      "1                                                          0.0      \n",
      "2                                                          0.0      \n",
      "3                                                          1.0      \n",
      "4                                                          0.0      \n",
      "\n",
      "description  quick and easy to put together.  \n",
      "0                                   0.550112  \n",
      "1                                   0.000000  \n",
      "2                                   0.000000  \n",
      "3                                   0.000000  \n",
      "4                                   1.000000  \n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "si = []\n",
    "for i in range(vectors.shape[0]):\n",
    "    row = []\n",
    "    for j in range(vectors.shape[0]):\n",
    "        sim = 1 - cosine(vectors[i].toarray(), vectors[j].toarray())\n",
    "        row.append(sim)\n",
    "    si.append(row)\n",
    "\n",
    "s_df = pd.DataFrame(si, columns=random_recipes['description'])\n",
    "\n",
    "print(s_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Какие рецепты являются наиболее похожими? Прокомментируйте результат (словами)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Наиболее похожими являютя рецепты №1 и №5, их схожесть обуславливается тем, что их 'quick and easy' готовить)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
